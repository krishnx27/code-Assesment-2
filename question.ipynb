{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN98EoYR/UyN7Z7xO3eIc/x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krishnx27/code-Assesment-2/blob/main/question.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Badp9WyIcmz_"
      },
      "outputs": [],
      "source": [
        "import re\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This line imports the re library, which provides functions for working with regular expressions. We'll use it later to split strings into tokens (words or alphanumeric sequences)"
      ],
      "metadata": {
        "id": "B6aETsM-kRYY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def levenshtein(str1, str2):\n",
        "\n",
        "  n_m = [[0 for _ in range(len(str2) + 1)] for _ in range(len(str1) + 1)]\n",
        "  for i in range(len(str1) + 1):\n",
        "    n_m[i][0] = i\n",
        "  for j in range(len(str2) + 1):\n",
        "    n_m[0][j] = j\n",
        "  for i in range(1, len(str1) + 1):\n",
        "    for j in range(1, len(str2) + 1):\n",
        "      if str1[i - 1] == str2[j - 1]:\n",
        "        n_m[i][j] = n_m[i - 1][j - 1]\n",
        "      else:\n",
        "        insertion = n_m[i][j - 1] + 1\n",
        "        deletion = n_m[i - 1][j] + 1\n",
        "        substitution = n_m[i - 1][j - 1] + 1\n",
        "        n_m[i][j] = min(insertion, deletion, substitution)\n",
        "  return n_m[-1][-1]\n"
      ],
      "metadata": {
        "id": "hXsE8dxDcqXE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The levenshtein function calculates the minimum edit distance between two strings.This defines a function called levenshtein that takes two strings (str1 and str2) as arguments.\n",
        "It calculates the Levenshtin distance between them using a dynamic programing approach.\n",
        "The function creates a 2D table (n_m) where each cell represents the minimum number of edits needed to transform a prefix of str1 (up to a certain index) into a prefix of str2 (up to a certain index).\n",
        "It iterates through the table, calculating the minimum edit distance based on insertions, deletions, or substitutions of characters.\n",
        "Finally, it returns the value at the bottom right corner of the table, which represents the Levenshtein distance between the entire str1 and str2..."
      ],
      "metadata": {
        "id": "5B24trL-jbj_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fuzzy_match(user_input, database_names, threshold=2):\n",
        "\n",
        "  # Uppercase for case-insensitive matching\n",
        "  user_input = user_input.upper()\n",
        "  database_names = [name.upper() for name in database_names]\n",
        "\n",
        "  user_tokens = re.findall(r'\\w+', user_input)  # Split into tokens (words/alphanumeric)\n",
        "  best_match, best_score = None, 0\n",
        "\n",
        "  for database_name in database_names:\n",
        "    database_tokens = re.findall(r'\\w+', database_name)\n",
        "    score = 0\n",
        "    for user_token in user_tokens:\n",
        "      min_distance = min(levenshtein(user_token, token) for token in database_tokens)\n",
        "      if min_distance <= threshold:\n",
        "        # Prioritize matches closer to the beginning (adjust weights as needed)\n",
        "        score += 100 - min_distance * 20\n",
        "    if score > best_score:\n",
        "      best_match, best_score = database_name, score\n",
        "\n",
        "  percentage = best_score / (len(user_tokens) * 100) if best_match else 0\n",
        "  return best_match, percentage\n",
        "\n",
        "# Example usage\n",
        "database_names = [\n",
        "  \"toyota_fortuner_legender\", \"toyota_fortuner\", \"toyota_camry\", \"tata_punch\", \"tata_tiago\"\n",
        "]\n",
        "user_input1 = \"tata_punch\"\n",
        "user_input2 = \"toyota_camry\"\n",
        "\n",
        "best_match1, score1 = fuzzy_match(user_input1, database_names)\n",
        "best_match2, score2 = fuzzy_match(user_input2, database_names)\n",
        "\n",
        "print(f\"Best match for '{user_input1}': {best_match1} ({score1:.2f}%)\")\n",
        "print(f\"Best match for '{user_input2}': {best_match2} ({score2:.2f}%)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ikF5xvsjcvEI",
        "outputId": "2b08904a-91f8-4019-f726-559605625b6a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best match for 'tata_punch': TATA_PUNCH (1.00%)\n",
            "Best match for 'toyota_camry': TOYOTA_CAMRY (1.00%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This defines a function called fuzzy_match that takes three arguments:\n",
        "user_input: The user's find the opnion ......"
      ],
      "metadata": {
        "id": "Tw2hq8HckbTu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fuzzy_match(user_input, database_names, threshold=2):\n",
        "\n",
        "  # Uppercase for case-insensitive matching\n",
        "  user_input = user_input.upper()\n",
        "  database_names = [name.upper() for name in database_names]\n",
        "\n",
        "  user_tokens = re.findall(r'\\w+', user_input)  # Split into tokens (words/alphanumeric)\n",
        "  best_match, best_score = None, 0\n",
        "\n",
        "  for database_name in database_names:\n",
        "    database_tokens = re.findall(r'\\w+', database_name)\n",
        "    score = 0\n",
        "    for user_token in user_tokens:\n",
        "      min_distance = min(levenshtein(user_token, token) for token in database_tokens)\n",
        "      if min_distance <= threshold:\n",
        "        # Prioritize matches closer to the beginning (adjust weights as needed)\n",
        "        score += 100 - min_distance * 20\n",
        "    if score > best_score:\n",
        "      best_match, best_score = database_name, score\n",
        "\n",
        "  percentage = best_score / (len(user_tokens) * 100) if best_match else 0\n",
        "  return best_match, percentage\n",
        "\n",
        "# Example usage\n",
        "database_names = [\n",
        "  \"jeep_compass\", \"kia_sonet\", \"kia_carens\", \"tata_punch\", \"tata_tiago\"\n",
        "]\n",
        "user_input1 = \"tata_punch\"\n",
        "user_input2 = \"maruti_suzuki_brezza\"\n",
        "\n",
        "best_match1, score1 = fuzzy_match(user_input1, database_names)\n",
        "best_match2, score2 = fuzzy_match(user_input2, database_names)\n",
        "\n",
        "print(f\"Best match for '{user_input1}': {best_match1} ({score1:.2f}%)\")\n",
        "print(f\"Best match for '{user_input2}': {best_match2} ({score2:.2f}%)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "m4JKmsRFgpN2",
        "outputId": "13f2b64f-ecfb-412c-c528-d1d368f0dd23"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best match for 'tata_punch': TATA_PUNCH (1.00%)\n",
            "Best match for 'maruti_suzuki_brezza': None (0.00%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*So I tried it on some data sets given below and the answers are also given there.*"
      ],
      "metadata": {
        "id": "AE-6BEViiswU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fuzzy_match(user_input, database_names, threshold=2):\n",
        "\n",
        "  # Uppercase for case-insensitive matching\n",
        "  user_input = user_input.upper()\n",
        "  database_names = [name.upper() for name in database_names]\n",
        "\n",
        "  user_tokens = re.findall(r'\\w+', user_input)  # Split into tokens (words/alphanumeric)\n",
        "  best_match, best_score = None, 0\n",
        "\n",
        "  for database_name in database_names:\n",
        "    database_tokens = re.findall(r'\\w+', database_name)\n",
        "    score = 0\n",
        "    for user_token in user_tokens:\n",
        "      min_distance = min(levenshtein(user_token, token) for token in database_tokens)\n",
        "      if min_distance <= threshold:\n",
        "        # Prioritize matches closer to the beginning (adjust weights as needed)\n",
        "        score += 100 - min_distance * 20\n",
        "    if score > best_score:\n",
        "      best_match, best_score = database_name, score\n",
        "\n",
        "  percentage = best_score / (len(user_tokens) * 100) if best_match else 0\n",
        "  return best_match, percentage\n",
        "\n",
        "# Example usage\n",
        "database_names = [\n",
        "  \"skoda_slavia\", \"toyota_camry\", \"toyota_glanza\", \"toyota_innova_crysta\", \"skoda_kushaq\"\n",
        "]\n",
        "user_input1 = \"tata_punch\"\n",
        "user_input2 = \"maruti_suzuki_brezza\"\n",
        "\n",
        "best_match1, score1 = fuzzy_match(user_input1, database_names)\n",
        "best_match2, score2 = fuzzy_match(user_input2, database_names)\n",
        "\n",
        "print(f\"Best match for '{user_input1}': {best_match1} ({score1:.2f}%)\")\n",
        "print(f\"Best match for '{user_input2}': {best_match2} ({score2:.2f}%)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "KQ_xMlY6hPhd",
        "outputId": "ce0c8f47-f38d-49ab-82fb-04dfb36c1d6b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best match for 'tata_punch': None (0.00%)\n",
            "Best match for 'maruti_suzuki_brezza': None (0.00%)\n"
          ]
        }
      ]
    }
  ]
}